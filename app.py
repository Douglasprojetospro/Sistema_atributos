import streamlit as st
import pandas as pd
from io import BytesIO
import re
import tempfile
import os
from pathlib import Path
import time

# ==================================================
# CONFIGURA√á√ïES INICIAIS E OTIMIZA√á√ïES
# ==================================================

# Configura√ß√µes espec√≠ficas para Render
def is_render():
    """Detecta se est√° executando no ambiente Render"""
    return 'RENDER' in os.environ or ('HOSTNAME' in os.environ and 'render' in os.environ['HOSTNAME'])

# Configura√ß√µes da p√°gina
st.set_page_config(
    page_title="Processador de Planilhas - Otimizado", 
    page_icon="üìä", 
    layout="wide",
    initial_sidebar_state="expanded"
)

# Configura√ß√µes do pandas para melhor performance
pd.set_option('mode.chained_assignment', None)
pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', 100)

# Otimiza√ß√µes espec√≠ficas para Render
if is_render():
    MAX_ROWS_RENDER = 50000  # Limite conservador para Render
    st.markdown("""
    <style>
    .main .block-container {
        padding-top: 2rem;
        padding-bottom: 2rem;
    }
    .stProgress > div > div > div > div {
        background-color: #1f77b4;
    }
    </style>
    """, unsafe_allow_html=True)
else:
    MAX_ROWS_RENDER = 200000  # Limite maior para execu√ß√£o local

# ==================================================
# FUN√á√ïES AUXILIARES
# ==================================================

def to_excel(df):
    """
    Converte DataFrame para Excel em mem√≥ria
    """
    output = BytesIO()
    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
        df.to_excel(writer, index=False, sheet_name='Resultado')
        
        # Formata√ß√£o b√°sica
        workbook = writer.book
        worksheet = writer.sheets['Resultado']
        format_header = workbook.add_format({'bold': True, 'bg_color': '#366092', 'font_color': 'white'})
        
        # Formatar cabe√ßalho
        for col_num, value in enumerate(df.columns.values):
            worksheet.write(0, col_num, value, format_header)
            
    output.seek(0)
    return output.getvalue()

def ler_arquivo_eficiente(arquivo):
    """
    L√™ arquivo Excel de forma otimizada para diferentes tamanhos
    """
    try:
        # Criar arquivo tempor√°rio
        temp_dir = tempfile.mkdtemp()
        temp_path = os.path.join(temp_dir, arquivo.name)
        
        with open(temp_path, 'wb') as f:
            f.write(arquivo.getvalue())
        
        # Verificar tamanho do arquivo
        tamanho_mb = os.path.getsize(temp_path) / (1024 * 1024)
        st.info(f"üìÅ Tamanho do arquivo: {tamanho_mb:.2f} MB")
        
        # Estrat√©gias diferentes baseadas no tamanho
        if tamanho_mb > 50:
            st.warning("‚ö° Arquivo grande detectado. Usando modo de leitura otimizado...")
            
            # Ler metadados primeiro
            xl = pd.ExcelFile(temp_path)
            primeira_linha = pd.read_excel(temp_path, nrows=1)
            
            # Verificar colunas necess√°rias
            colunas_necessarias = ['ID', 'Descri√ß√£o']
            colunas_disponiveis = [col for col in colunas_necessarias if col in primeira_linha.columns]
            
            if len(colunas_disponiveis) == len(colunas_necessarias):
                # Ler apenas colunas necess√°rias
                df = pd.read_excel(
                    temp_path,
                    usecols=colunas_necessarias,
                    dtype={'ID': 'str', 'Descri√ß√£o': 'str'},
                    engine='openpyxl'
                )
            else:
                # Ler todas as colunas
                df = pd.read_excel(temp_path, engine='openpyxl')
                
        else:
            # Leitura normal para arquivos menores
            df = pd.read_excel(temp_path, engine='openpyxl')
        
        # Limpeza
        os.remove(temp_path)
        os.rmdir(temp_dir)
        
        return df
        
    except Exception as e:
        st.error(f"‚ùå Erro ao ler arquivo: {str(e)}")
        # Tentativa de fallback
        try:
            return pd.read_excel(arquivo, engine='openpyxl')
        except:
            return None

def processar_em_lotes(data_df, config_df, tamanho_lote=1000):
    """
    Processa os dados em lotes para economizar mem√≥ria
    """
    # Pr√©-processar configura√ß√µes
    config_groups = config_df.groupby('Atributo')
    config_dict = {}
    
    for attr, group in config_groups:
        config_dict[attr] = []
        for _, row in group.iterrows():
            patterns = [p.strip().lower() for p in str(row['Padr√£o de reconhecimento']).split(',') if p.strip()]
            config_dict[attr].append({
                'variation': str(row['Varia√ß√£o']),
                'patterns': patterns
            })
    
    # Processar em lotes
    resultados = []
    total_linhas = len(data_df)
    
    for i in range(0, total_linhas, tamanho_lote):
        lote = data_df.iloc[i:i + tamanho_lote].copy()
        
        for attr, configs in config_dict.items():
            coluna_resultado = []
            
            for _, linha in lote.iterrows():
                descricao = str(linha['Descri√ß√£o']).lower()
                variacoes_encontradas = []
                
                for config in configs:
                    for pattern in config['patterns']:
                        if pattern and re.search(r'\b' + re.escape(pattern) + r'\b', descricao):
                            if config['variation'] not in variacoes_encontradas:
                                variacoes_encontradas.append(config['variation'])
                            break
                
                coluna_resultado.append(', '.join(variacoes_encontradas) if variacoes_encontradas else '')
            
            lote[attr] = coluna_resultado
        
        resultados.append(lote)
        
        # Atualizar progresso
        progresso = min((i + len(lote)) / total_linhas, 1.0)
        yield progresso, lote
    
    # Retornar resultado final
    if resultados:
        result_df = pd.concat(resultados, ignore_index=True)
        yield 1.0, result_df
    else:
        yield 1.0, pd.DataFrame()

def processamento_direto(data_df, config_df):
    """
    Processamento direto para arquivos pequenos
    """
    config_groups = config_df.groupby('Atributo')
    result_df = data_df.copy()
    
    total_attrs = len(config_groups)
    progress_bar = st.progress(0)
    
    for i, (attr, group) in enumerate(config_groups):
        progress_bar.progress(i / total_attrs)
        
        variations_list = []
        for _, data_row in data_df.iterrows():
            descricao = str(data_row['Descri√ß√£o']).lower()
            matched_variations = []
            
            for _, config_row in group.iterrows():
                patterns = [p.strip().lower() for p in str(config_row['Padr√£o de reconhecimento']).split(',') if p.strip()]
                variation = str(config_row['Varia√ß√£o'])
                
                for pattern in patterns:
                    if pattern and re.search(r'\b' + re.escape(pattern) + r'\b', descricao):
                        if variation not in matched_variations:
                            matched_variations.append(variation)
                        break
            
            variations_list.append(', '.join(matched_variations) if matched_variations else '')
        
        result_df[attr] = variations_list
    
    progress_bar.progress(1.0)
    return result_df

# ==================================================
# INTERFACE DO USU√ÅRIO
# ==================================================

st.title("üìä Processador de Planilhas - Otimizado para Grandes Arquivos")
st.markdown("""
*Processe grandes volumes de dados de forma eficiente com reconhecimento de padr√µes em descri√ß√µes de produtos.*
""")
st.markdown("---")

# ==================================================
# SE√á√ÉO DE TEMPLATES
# ==================================================

st.subheader("üìã Modelos para Download")

col1, col2 = st.columns(2)

with col1:
    # Template de dados
    data_template = pd.DataFrame({
        'ID': [1414, 2525, 3636, 4747],
        'Descri√ß√£o': [
            'Ventilador de teto 110 amarelo biv', 
            'Lumin√°ria LED 220v branca',
            'L√¢mpada LED 12W 127V quente',
            'Sensor movimento 220v preto'
        ]
    })
    
    st.download_button(
        "üì• Baixar modelo de dados", 
        to_excel(data_template), 
        file_name="modelo_dados.xlsx",
        help="Modelo da planilha com colunas ID e Descri√ß√£o",
        type="secondary"
    )
    
    st.dataframe(data_template, use_container_width=True)

with col2:
    # Template de configura√ß√µes
    config_template = pd.DataFrame({
        'Atributo': ['Voltagem', 'Voltagem', 'Voltagem', 'Cor', 'Cor', 'Tipo', 'Tipo'],
        'Varia√ß√£o': ['110v', '220v', 'Bivolt', 'Amarelo', 'Branca', 'LED', 'Sensor'],
        'Padr√£o de reconhecimento': [
            '110,110v,127', 
            '220,220v,227', 
            'bivolt,biv', 
            'amarelo,yellow', 
            'branca,white',
            'led,l√¢mpada,light',
            'sensor,detector,movimento'
        ]
    })
    
    st.download_button(
        "üì• Baixar modelo de configura√ß√µes", 
        to_excel(config_template), 
        file_name="modelo_config.xlsx",
        help="Modelo da planilha com colunas Atributo, Varia√ß√£o e Padr√£o de reconhecimento",
        type="secondary"
    )
    
    st.dataframe(config_template, use_container_width=True)

st.markdown("---")

# ==================================================
# SE√á√ÉO DE UPLOAD
# ==================================================

st.subheader("üì§ Upload dos Arquivos")

upload_col1, upload_col2 = st.columns(2)

with upload_col1:
    st.info("""
    **üìä Planilha de Dados:**
    - Colunas obrigat√≥rias: **ID** e **Descri√ß√£o**
    - Suporta outras colunas adicionais
    - Formatos suportados: XLSX
    """)
    data_file = st.file_uploader("Planilha de dados", type="xlsx", key="data_upload")

with upload_col2:
    st.info("""
    **‚öôÔ∏è Planilha de Configura√ß√µes:**
    - Colunas obrigat√≥rias: **Atributo**, **Varia√ß√£o**, **Padr√£o de reconhecimento**
    - Padr√µes separados por v√≠rgula
    - Formatos suportados: XLSX
    """)
    config_file = st.file_uploader("Planilha de configura√ß√µes", type="xlsx", key="config_upload")

# ==================================================
# PROCESSAMENTO PRINCIPAL
# ==================================================

if data_file and config_file:
    try:
        # Ler arquivos
        st.subheader("üìñ Lendo Arquivos...")
        
        with st.spinner("Carregando arquivos..."):
            config_df = pd.read_excel(config_file)
            data_df = ler_arquivo_eficiente(data_file)
        
        if data_df is None:
            st.error("‚ùå Erro ao ler arquivo de dados. Verifique o formato do arquivo.")
            st.stop()
        
        # Validar colunas
        required_data_cols = ['ID', 'Descri√ß√£o']
        required_config_cols = ['Atributo', 'Varia√ß√£o', 'Padr√£o de reconhecimento']
        
        if not all(col in data_df.columns for col in required_data_cols):
            st.error(f"‚ùå Planilha de dados deve conter as colunas: {required_data_cols}")
            st.write("üìã Colunas encontradas:", list(data_df.columns))
            st.stop()
            
        if not all(col in config_df.columns for col in required_config_cols):
            st.error(f"‚ùå Planilha de configura√ß√µes deve conter as colunas: {required_config_cols}")
            st.write("üìã Colunas encontradas:", list(config_df.columns))
            st.stop()
        
        # Mostrar estat√≠sticas
        st.subheader("üìä Estat√≠sticas dos Dados")
        
        info_col1, info_col2, info_col3, info_col4 = st.columns(4)
        
        with info_col1:
            st.metric("Linhas de dados", f"{len(data_df):,}")
        
        with info_col2:
            st.metric("Colunas de dados", len(data_df.columns))
        
        with info_col3:
            atributos_unicos = len(config_df['Atributo'].unique())
            st.metric("Atributos configurados", atributos_unicos)
        
        with info_col4:
            tamanho_memoria = data_df.memory_usage(deep=True).sum() / (1024 * 1024)
            st.metric("Uso de mem√≥ria (MB)", f"{tamanho_memoria:.1f}")
        
        # Configura√ß√µes de processamento
        st.subheader("‚öôÔ∏è Configura√ß√µes de Processamento")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if is_render():
                if len(data_df) > MAX_ROWS_RENDER:
                    st.error(f"‚ö†Ô∏è Arquivo muito grande para o Render (limite: {MAX_ROWS_RENDER} linhas)")
                    usar_lotes = True
                else:
                    usar_lotes = len(data_df) > 5000
            else:
                usar_lotes = st.checkbox("Usar processamento em lotes", 
                                       value=len(data_df) > 5000,
                                       help="Recomendado para arquivos grandes")
        
        with col2:
            if usar_lotes:
                tamanho_lote = st.selectbox("Tamanho do lote", 
                                          [500, 1000, 2000, 5000], 
                                          index=1,
                                          help="N√∫mero de linhas processadas por vez")
            else:
                tamanho_lote = 1000
                st.info("üîß Processamento direto")
        
        with col3:
            mostrar_preview = st.checkbox("Mostrar preview", value=True)
        
        # Preview dos dados
        if mostrar_preview:
            st.subheader("üëÄ Preview dos Dados")
            
            preview_col1, preview_col2 = st.columns(2)
            
            with preview_col1:
                st.write("**üìä Planilha de Dados** (primeiras 5 linhas)")
                st.dataframe(data_df.head(), use_container_width=True)
            
            with preview_col2:
                st.write("**‚öôÔ∏è Planilha de Configura√ß√µes**")
                st.dataframe(config_df, use_container_width=True)
        
        # Processamento
        st.subheader("‚öôÔ∏è Processando Dados...")
        start_time = time.time()
        
        if usar_lotes and len(data_df) > 1000:
            st.info(f"üîß Processando em lotes de {tamanho_lote} linhas...")
            
            # Interface de progresso
            progress_bar = st.progress(0)
            status_text = st.empty()
            time_elapsed = st.empty()
            
            resultados_parciais = []
            linhas_processadas = 0
            
            for progresso, lote_processado in processar_em_lotes(data_df, config_df, tamanho_lote):
                progress_bar.progress(progresso)
                linhas_processadas = min((progresso * len(data_df)), len(data_df))
                tempo_decorrido = time.time() - start_time
                
                status_text.text(f"üìà Progresso: {progresso*100:.1f}%")
                time_elapsed.text(f"‚è±Ô∏è Tempo decorrido: {tempo_decorrido:.1f}s")
                
                if progresso < 1.0:
                    resultados_parciais.append(lote_processado)
                else:
                    result_df = lote_processado
            
            status_text.text("‚úÖ Processamento conclu√≠do!")
            time_elapsed.text(f"‚è±Ô∏è Tempo total: {time.time() - start_time:.1f}s")
            
        else:
            st.info("üîß Processamento direto...")
            result_df = processamento_direto(data_df, config_df)
        
        processing_time = time.time() - start_time
        
        # Resultado final
        st.subheader("üìä Resultado Final")
        
        # Mostrar amostra se for muito grande
        if len(result_df) > 1000:
            st.warning(f"üìã Mostrando as primeiras 1000 linhas de {len(result_df):,} totais")
            st.dataframe(result_df.head(1000), use_container_width=True)
        else:
            st.dataframe(result_df, use_container_width=True)
        
        # Estat√≠sticas finais
        st.subheader("üìà Estat√≠sticas do Processamento")
        
        stat_col1, stat_col2, stat_col3, stat_col4 = st.columns(4)
        
        with stat_col1:
            total_matches = 0
            for attr in config_df['Atributo'].unique():
                if attr in result_df.columns:
                    total_matches += (result_df[attr].str.count(',') + 1).where(result_df[attr] != '', 0).sum()
            st.metric("Total de Correspond√™ncias", f"{int(total_matches):,}")
        
        with stat_col2:
            atributos_com_match = sum([1 for attr in config_df['Atributo'].unique() 
                                     if attr in result_df.columns and result_df[attr].ne('').any()])
            st.metric("Atributos com Match", atributos_com_match)
        
        with stat_col3:
            if all(attr in result_df.columns for attr in config_df['Atributo'].unique()):
                linhas_com_match = result_df[config_df['Atributo'].unique()].ne('').any(axis=1).sum()
                st.metric("Linhas com Match", f"{linhas_com_match:,}")
            else:
                st.metric("Linhas com Match", "N/A")
        
        with stat_col4:
            st.metric("Tempo de Processamento", f"{processing_time:.1f}s")
        
        # Download do resultado
        st.subheader("üì• Download do Resultado")
        
        if len(result_df) > 50000:
            st.warning("üí° Arquivo muito grande. Recomendamos dividir o download:")
            
            partes = (len(result_df) // 50000) + 1
            for i in range(partes):
                inicio = i * 50000
                fim = min((i + 1) * 50000, len(result_df))
                parte_df = result_df.iloc[inicio:fim]
                
                parte_excel = to_excel(parte_df)
                st.download_button(
                    f"üíæ Baixar Parte {i+1} (linhas {inicio+1}-{fim})", 
                    parte_excel, 
                    file_name=f"relatorio_parte_{i+1}.xlsx",
                    help=f"Parte {i+1} do relat√≥rio"
                )
        else:
            result_excel = to_excel(result_df)
            
            st.download_button(
                "üíæ Baixar Relat√≥rio Completo", 
                result_excel, 
                file_name="relatorio_processado.xlsx",
                help="Planilha com os resultados do processamento",
                type="primary"
            )
        
        st.success(f"‚úÖ Processamento conclu√≠do com sucesso em {processing_time:.1f} segundos!")
        
    except Exception as e:
        st.error(f"‚ùå Erro durante o processamento: {str(e)}")
        st.info("üí° Para arquivos muito grandes, tente dividi-los em partes menores.")

else:
    st.info("üëÜ Fa√ßa o upload de ambas as planilhas para iniciar o processamento.")

# ==================================================
# SE√á√ïES INFORMATIVAS
# ==================================================

with st.expander("üöÄ Estrat√©gias para Arquivos MUITO Grandes (500MB+)"):
    st.markdown("""
    ### üìè Se seus arquivos forem maiores que 500MB:
    
    **1. Divida os arquivos de dados:**
    - Separe em m√∫ltiplos arquivos de ~100MB cada
    - Processe um por um
    - Combine os resultados depois
    
    **2. Use um servidor com mais recursos:**
    - Aumente a mem√≥ria RAM dispon√≠vel
    - Use inst√¢ncias com melhor processamento
    
    **3. Otimize suas planilhas:**
    - Remova colunas desnecess√°rias
    - Use compacta√ß√£o ZIP nos arquivos XLSX
    - Converta para CSV (menor tamanho)
    
    **4. Processamento em nuvem:**
    - Use servi√ßos como AWS, Google Cloud
    - Processe em m√°quinas mais potentes
    """)

with st.expander("üí° Como Funciona o Reconhecimento de Padr√µes"):
    st.markdown("""
    ### üîç Exemplo de Funcionamento:
    
    **Descri√ß√£o do produto:**
    ```
    "Ventilador de teto 110 amarelo biv"
    ```
    
    **Configura√ß√£o de Voltagem:**
    - Padr√£o: `110,110v,127`
    - Varia√ß√£o: `110v`
    
    **Resultado:** A coluna "Voltagem" ser√° preenchida com `110v`
    
    ### ‚ö†Ô∏è Regras do Reconhecimento:
    - Busca por **palavras completas** (usando `\\b` no regex)
    - **Case insensitive** (n√£o diferencia mai√∫sculas/min√∫sculas)
    - **M√∫ltiplos padr√µes** separados por v√≠rgula
    - **Primeira correspond√™ncia** prevalece
    """)

with st.expander("üìã Estrutura dos Arquivos"):
    st.markdown("""
    ### üìä Planilha de Dados:
    | ID | Descri√ß√£o |
    |----|-----------|
    | 1414 | Ventilador de teto 110 amarelo biv |
    | 2525 | Lumin√°ria LED 220v branca |
    
    ### ‚öôÔ∏è Planilha de Configura√ß√µes:
    | Atributo | Varia√ß√£o | Padr√£o de reconhecimento |
    |----------|----------|--------------------------|
    | Voltagem | 110v | 110,110v,127 |
    | Voltagem | 220v | 220,220v,227 |
    | Cor | Amarelo | amarelo,yellow |
    """)

with st.expander("‚öôÔ∏è Configura√ß√µes T√©cnicas"):
    st.markdown(f"""
    ### üõ†Ô∏è Configura√ß√µes do Sistema:
    - **Limite Render:** {MAX_ROWS_RENDER:,} linhas
    - **Processamento em lotes:** Ativado automaticamente > 5.000 linhas
    - **Tamanho m√°ximo de lote:** 5.000 linhas
    - **Formato suportado:** XLSX
    
    ### üìä Performance Esperada:
    - **At√© 10.000 linhas:** 10-30 segundos
    - **10.000-50.000 linhas:** 1-5 minutos  
    - **50.000+ linhas:** 5+ minutos (depende do hardware)
    """)

# ==================================================
# RODAP√â
# ==================================================

st.markdown("---")
st.markdown("""
<div style='text-align: center; color: #666;'>
    <p>Desenvolvido com Streamlit ‚Ä¢ Otimizado para grandes arquivos ‚Ä¢ Vers√£o 2.0</p>
</div>
""", unsafe_allow_html=True)

# Limpeza de cache para produ√ß√£o
if is_render():
    try:
        if hasattr(st, 'cache_data'):
            st.cache_data.clear()
        if hasattr(st, 'cache_resource'):
            st.cache_resource.clear()
    except:
        pass
